{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# PEFT를 활용한 LLM Fine-tuning시키기 (with Transformers🤗 & bitsandbytes)\n",
        "이 튜토리얼에서는 8비트로 큰 모델을 로드하기 위해 최신 peft 라이브러리를 사용하여 LLM을 파인튜닝하는 방법을 다룰 것입니다. 파인튜닝 방법은 전체 모델의 가중치를 조정하는 대신 어댑터를 튜닝시키고 모델 내부에 적절하게 로드하기만 하면 되는 \"LoRA\"라는 최신 방법을 사용합니다. 모델을 파인튜닝한 후에는 허깅페이스🤗 허브에서 어댑터를 공유하여 매우 쉽게 로드할 수도 있습니다. 확인해보시죠!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xk5l_r7RZx3A"
      },
      "outputs": [],
      "source": [
        "# 훈련에 필요한 패키지들을 설치합니다 / 지금 버젼은 구글 코랩 사용자를 대상으로 설치를 가이드 합니다.\n",
        "!pip install transformers[torch] peft datasets sentencepiece evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "uJl3pL7bDvsG"
      },
      "outputs": [],
      "source": [
        "from dataclasses import dataclass, field\n",
        "from typing import Any, Dict, List, Optional, Union\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from datasets import load_dataset\n",
        "from peft import LoraConfig, TaskType, get_peft_model\n",
        "import sentencepiece\n",
        "\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# RLHF에 쓰이는 Reward Model을 파인튜닝 시키기 위한 데이터와 Base Model 준비하기\n",
        "\n",
        "두 문장을 비교하여 얼마나 유사한지 또는 얼마나 잘 따랐는지(Align) 예측할 수 있는 모델을 만들기 위해 다음과 같은 데이터를 사용하여 2가지 feature를 input으로 받는 LLM을 파인튜닝 시키겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "qu_oudCmHYUL"
      },
      "outputs": [],
      "source": [
        "train_dataset = load_dataset(\"fiveflow/cot_ranking\", split=\"train\")\n",
        "eval_dataset = load_dataset(\"fiveflow/cot_ranking\", split=\"test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 데이터를 파악하니 question과 j,k 응답이 있습니다. 자세한 설명을 드리지 않았지만 지금 사용하는 데이터셋은 저희가 만든 데이터셋이고, LLM이 스스로 J응답이 K응답보다 더 좋다고 판단하여 구축한 데이터입니다.\n",
        "# 따라서 J응답은 (LLM 기준) 항상 K응답보다 더 나은 Preference를 갖습니다.\n",
        "train_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_dataset[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFNJuvFHHsq_",
        "outputId": "c1aa16ef-d54a-43fa-98d8-76ce72e2a6ed"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of OPTForSequenceClassification were not initialized from the model checkpoint at facebook/opt-iml-max-1.3b and are newly initialized: ['score.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "\n",
        "rank_model, tokenizer = AutoModelForSequenceClassification.from_pretrained(\"facebook/opt-iml-max-1.3b\", num_labels=1),AutoTokenizer.from_pretrained(\"facebook/opt-iml-max-1.3b\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "RlCrWUfRIS4U"
      },
      "outputs": [],
      "source": [
        "# 데이터셋의 전처리 과정입니다. question에 대한 j응답과 k응답을 비교하고 싶기 때문에 (question + j응답, question + k응답) 쌍으로 데이터를 구축합니다.\n",
        "\"\"\"\n",
        "num_proc은 인프라 환경에 따라 1로 두셔도 좋습니다.\n",
        "original columns를 제거하는 이유는 쓸데없는 데이터가 메모리 차지하는 것을 방지하기 위함입니다.\n",
        "max_length 또한 인프라 환경에 따라 변경하셔도 좋습니다. 단, question과 응답을 합친것이 한 Input이기 때문에 데이터를 확인하여 짤려도 괜찮다고 생각했을 경우 사용하는 것을 권장합니다.\n",
        "\"\"\"\n",
        "\n",
        "num_proc = 24\n",
        "original_columns = train_dataset.column_names\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    new_examples = {\n",
        "            \"input_ids_j\": [],\n",
        "            \"attention_mask_j\": [],\n",
        "            \"input_ids_k\": [],\n",
        "            \"attention_mask_k\": [],\n",
        "        }\n",
        "    for question, response_j, response_k in zip(examples[\"question\"], examples[\"response_j\"], examples[\"response_k\"]):\n",
        "        tokenized_j = tokenizer(\"Question: \" + question + \"\\n\\nAnswer: \" + response_j)\n",
        "        tokenized_k = tokenizer(\"Question: \" + question + \"\\n\\nAnswer: \" + response_k)\n",
        "\n",
        "        new_examples[\"input_ids_j\"].append(tokenized_j[\"input_ids\"])\n",
        "        new_examples[\"attention_mask_j\"].append(tokenized_j[\"attention_mask\"])\n",
        "        new_examples[\"input_ids_k\"].append(tokenized_k[\"input_ids\"])\n",
        "        new_examples[\"attention_mask_k\"].append(tokenized_k[\"attention_mask\"])\n",
        "\n",
        "    return new_examples\n",
        "\n",
        "\n",
        "max_length = 1024\n",
        "train_dataset = train_dataset.map(\n",
        "    preprocess_function, batched=True, num_proc=num_proc, remove_columns=original_columns\n",
        "    )\n",
        "train_dataset = train_dataset.filter(lambda x: len(x[\"input_ids_j\"]) <= max_length and len(x[\"input_ids_k\"]) <= max_length)\n",
        "\n",
        "eval_dataset = eval_dataset.map(preprocess_function, batched=True, num_proc=num_proc, remove_columns=original_columns)\n",
        "eval_dataset = eval_dataset.filter(lambda x: len(x[\"input_ids_j\"]) <= max_length and len(x[\"input_ids_k\"]) <= max_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "VjT9ws0uIS2t"
      },
      "outputs": [],
      "source": [
        "# 다음은 padding 전략입니다. 모든 데이터중 가장 긴 문장에 대해 padding을 하게 된다면 연산이 쓸데 없이 길어질 수 있습니다. \n",
        "# 따라서 한 batch안에서 가장 긴 문장에 대해 padding을 한다면 더 효과적일 것 입니다.\n",
        "\n",
        "from transformers import PreTrainedTokenizerBase\n",
        "from transformers.utils import PaddingStrategy\n",
        "import evaluate\n",
        "\n",
        "@dataclass\n",
        "class RewardDataCollatorWithPadding:\n",
        "    tokenizer: PreTrainedTokenizerBase\n",
        "    padding: Union[bool, str, PaddingStrategy] = True\n",
        "    max_length: Optional[int] = None\n",
        "    pad_to_multiple_of: Optional[int] = None\n",
        "    return_tensors: str = \"pt\"\n",
        "\n",
        "    def __call__(self, features: List[Dict[str, Any]]) -> Dict[str, Any]:\n",
        "        features_j = []\n",
        "        features_k = []\n",
        "        for feature in features:\n",
        "            features_j.append(\n",
        "                {\n",
        "                    \"input_ids\": feature[\"input_ids_j\"],\n",
        "                    \"attention_mask\": feature[\"attention_mask_j\"],\n",
        "                }\n",
        "            )\n",
        "            features_k.append(\n",
        "                {\n",
        "                    \"input_ids\": feature[\"input_ids_k\"],\n",
        "                    \"attention_mask\": feature[\"attention_mask_k\"],\n",
        "                }\n",
        "            )\n",
        "        batch_j = self.tokenizer.pad(\n",
        "            features_j,\n",
        "            padding=self.padding,\n",
        "            max_length=self.max_length,\n",
        "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
        "            return_tensors=self.return_tensors,\n",
        "        )\n",
        "        batch_k = self.tokenizer.pad(\n",
        "            features_k,\n",
        "            padding=self.padding,\n",
        "            max_length=self.max_length,\n",
        "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
        "            return_tensors=self.return_tensors,\n",
        "        )\n",
        "        batch = {\n",
        "            \"input_ids_j\": batch_j[\"input_ids\"],\n",
        "            \"attention_mask_j\": batch_j[\"attention_mask\"],\n",
        "            \"input_ids_k\": batch_k[\"input_ids\"],\n",
        "            \"attention_mask_k\": batch_k[\"attention_mask\"],\n",
        "            \"return_loss\": True,\n",
        "        }\n",
        "        return batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 메트릭 정의입니다.\n",
        "accuracy = evaluate.load(\"accuracy\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, _ = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=0)\n",
        "    labels = np.zeros(predictions.shape, dtype=int)\n",
        "    return accuracy.compute(predictions=predictions, references=labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "SNnIShEXIS0c"
      },
      "outputs": [],
      "source": [
        "# 허깅페이스에서 제공하는 trainer 중 loss 부분을 수정하여 사용합니다. 이유는 j응답과 k응답을 비교해야하는데 AutoModelForSequenceClassification으로 불러온 모델을 그대로 사용하기에는 부적절하기 때문입니다.\n",
        "# 따라서 Input을 두번 받고 그 logit값을 비교하여 j 응답에 더 가깝게 훈련하도록 RLHF에서 제안한 negative log sigmoid함수를 사용하여 다음과 같이 훈련하도록 선언합니다.\n",
        "\n",
        "from transformers import Trainer\n",
        "class RewardTrainer(Trainer):\n",
        "    def compute_loss(self, model, inputs, return_outputs=False):\n",
        "        rewards_j = model(input_ids=inputs[\"input_ids_j\"], attention_mask=inputs[\"attention_mask_j\"])[0]\n",
        "        rewards_k = model(input_ids=inputs[\"input_ids_k\"], attention_mask=inputs[\"attention_mask_k\"])[0]\n",
        "        loss = -nn.functional.logsigmoid(rewards_j - rewards_k).mean()\n",
        "        if return_outputs:\n",
        "            return loss, {\"rewards_j\": rewards_j, \"rewards_k\": rewards_k}\n",
        "        return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# PEFT를 활용하여 훈련 모델 선언하기\n",
        "\n",
        "지금까지는 RLHF의 Reward Model을 훈련시키기까지 과정을 살펴보았지만, 구글 코랩을 사용하게 되면 opt iml 1.3b모델로도 벅찰 가능성이 매우 높습니다. Reward model이니 어느정도 성능만 나오면 된다 생각할 수 있지만, PPO에 의해 훈련하는 과정에서 reward model의 결과에 좌지우지 될 수 있으므로 Reward Modeling의 정확도는 매우 중요합니다. 따라서 가능한 사용 가능한 파라미터를 늘려 훈련을 꽉꽉 채우기 위해 LoRA를 사용하여 훈련을 시켜보도록 하겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wqU8XKKH5UM",
        "outputId": "a4b9c43a-089c-48e3-e4a0-096f4753ac11"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/peft/utils/other.py:122: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable params: 790,528 || all params: 1,316,548,608 || trainable%: 0.06004548523285515\n"
          ]
        }
      ],
      "source": [
        "# 기존의 AutoModelForSequenceClassification으로 불러온 모델에 LoRA 어댑터를 추가만 하면 되기 때문에 다음과 같은 config를 지정하고 get_peft_model을 사용하여 새로운 모델 선언만 해주면 끝입니다.\n",
        "\n",
        "\"\"\"\n",
        "task_type은 다양합니다. [CAUSAL_LM, FEATURE_EXTRACTION, QUESTION_ANS, SEQ_2_SEQ_LM, SEQ_CLS, TOKEN_CLS]가 있습니다. 저희는 j,k응답을 비교하여 score를 얻고 싶기 때문에 SEQ_CLS를 사용하겠습니다.\n",
        "r, lora_alpha, lora_dropout은 pdf에 있는 논문 설명으로 설명을 대체하겠습니다.\n",
        "\"\"\"\n",
        "\n",
        "from peft import prepare_model_for_int8_training\n",
        "model = prepare_model_for_int8_training(rank_model)\n",
        "peft_config = LoraConfig(\n",
        "    task_type=TaskType.SEQ_CLS,\n",
        "    inference_mode=False,\n",
        "    r=8,\n",
        "    lora_alpha=16,\n",
        "    lora_dropout=0.05,\n",
        "    target_modules=[\"j_proj\", \"k_proj\"]\n",
        ")\n",
        "lora_model = get_peft_model(model, peft_config)\n",
        "lora_model.print_trainable_parameters()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pM-FE4_5INYz",
        "outputId": "d066fa97-b411-4af0-c131-7395963bd00a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "OPTForSequenceClassification(\n",
              "  (model): OPTModel(\n",
              "    (decoder): OPTDecoder(\n",
              "      (embed_tokens): Embedding(50272, 2048, padding_idx=1)\n",
              "      (embed_positions): OPTLearnedPositionalEmbedding(2050, 2048)\n",
              "      (final_layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "      (layers): ModuleList(\n",
              "        (0-23): 24 x OPTDecoderLayer(\n",
              "          (self_attn): OPTAttention(\n",
              "            (k_proj): Linear(\n",
              "              in_features=2048, out_features=2048, bias=True\n",
              "              (lora_dropout): ModuleDict(\n",
              "                (default): Dropout(p=0.05, inplace=False)\n",
              "              )\n",
              "              (lora_A): ModuleDict(\n",
              "                (default): Linear(in_features=2048, out_features=8, bias=False)\n",
              "              )\n",
              "              (lora_B): ModuleDict(\n",
              "                (default): Linear(in_features=8, out_features=2048, bias=False)\n",
              "              )\n",
              "              (lora_embedding_A): ParameterDict()\n",
              "              (lora_embedding_B): ParameterDict()\n",
              "            )\n",
              "            (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
              "            (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
              "            (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
              "          )\n",
              "          (activation_fn): ReLU()\n",
              "          (self_attn_layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
              "          (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
              "          (final_layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (score): ModulesToSaveWrapper(\n",
              "    (original_module): Linear(in_features=2048, out_features=1, bias=False)\n",
              "    (modules_to_save): ModuleDict(\n",
              "      (default): Linear(in_features=2048, out_features=1, bias=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rank_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whIlbg_3J9A5",
        "outputId": "77b8f5b2-c596-4ad8-a3b5-7be84dbd7026"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PeftModelForSequenceClassification(\n",
              "  (base_model): LoraModel(\n",
              "    (model): OPTForSequenceClassification(\n",
              "      (model): OPTModel(\n",
              "        (decoder): OPTDecoder(\n",
              "          (embed_tokens): Embedding(50272, 2048, padding_idx=1)\n",
              "          (embed_positions): OPTLearnedPositionalEmbedding(2050, 2048)\n",
              "          (final_layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "          (layers): ModuleList(\n",
              "            (0-23): 24 x OPTDecoderLayer(\n",
              "              (self_attn): OPTAttention(\n",
              "                (k_proj): Linear(\n",
              "                  in_features=2048, out_features=2048, bias=True\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Dropout(p=0.05, inplace=False)\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=2048, out_features=8, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=8, out_features=2048, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                )\n",
              "                (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
              "                (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
              "                (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
              "              )\n",
              "              (activation_fn): ReLU()\n",
              "              (self_attn_layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "              (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
              "              (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
              "              (final_layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (score): ModulesToSaveWrapper(\n",
              "        (original_module): Linear(in_features=2048, out_features=1, bias=False)\n",
              "        (modules_to_save): ModuleDict(\n",
              "          (default): Linear(in_features=2048, out_features=1, bias=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lora_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "CUCox1dSJkv1"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='/content/drive/MyDrive/Colab Notebooks/project/rm_opt',\n",
        "    learning_rate=1e-5,\n",
        "    per_device_train_batch_size=1,\n",
        "    per_device_eval_batch_size=1,\n",
        "    num_train_epochs=2,\n",
        "    weight_decay=0.001,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    save_total_limit = 3,\n",
        "    eval_steps=500,\n",
        "    save_strategy=\"steps\",\n",
        "    save_steps=500,\n",
        "    gradient_accumulation_steps=1,\n",
        "    gradient_checkpointing=False,\n",
        "    deepspeed=None,\n",
        "    local_rank=-1,\n",
        "    remove_unused_columns=False,\n",
        "    label_names=[],\n",
        "    logging_strategy=\"steps\",\n",
        "    logging_steps=10,\n",
        "    optim=\"adamw_hf\",\n",
        "    lr_scheduler_type=\"linear\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "7zJ5acU0JcFt"
      },
      "outputs": [],
      "source": [
        "trainer = RewardTrainer(\n",
        "    model=lora_model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "    data_collator=RewardDataCollatorWithPadding(tokenizer=tokenizer, max_length=512),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "id": "rlTroeLAJjd1",
        "outputId": "f8750316-0139-4203-b733-9ff8ba79f57e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2640: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  warnings.warn(\n",
            "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='49' max='135660' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [    49/135660 00:26 < 21:22:21, 1.76 it/s, Epoch 0.00/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-3435b262f1ae>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1589\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1590\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1591\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   1592\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1593\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1869\u001b[0m             \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1870\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1871\u001b[0m                 \u001b[0mtotal_batched_samples\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1872\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mrng_to_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/data_loader.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    392\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m                     \u001b[0mcurrent_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msend_to_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m                 \u001b[0mnext_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskip_batches\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0mcurrent_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 629\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_profile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/profiler.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, exc_type, exc_value, traceback)\u001b[0m\n\u001b[1;32m    505\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_scripting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDisableTorchFunctionSubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m                 \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_function_exit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_RecordFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_function_exit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__hash__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f_Sc2JXoJn95"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
