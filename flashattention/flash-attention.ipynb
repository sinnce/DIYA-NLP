{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Matrices Q,K,V as (N * d) in HBM, SRAM Size of M\n",
    "N = 3\n",
    "d = 2\n",
    "\n",
    "\n",
    "Q = np.random.rand(N,d)\n",
    "K = np.random.rand(N,d)\n",
    "V = np.random.rand(N,d)\n",
    "M = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Set block size Bc = M/4d, Br = min(M/4d, d)\n",
    "B_c = M//(4*d)\n",
    "B_r = min(B_c, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Initialize\n",
    "O = np.zeros((N,d))\n",
    "l = np.zeros(N)\n",
    "m = np.full(N, -np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Divide Q into Tr which is N/B_r size of Br * d, K,V into Tr N/B_c Bc * d\n",
    "Q_blocks = np.array_split(Q, N // B_r) # np.array_split returns List of array\n",
    "K_blocks = np.array_split(K, N // B_c)\n",
    "V_blocks = np.array_split(V, N // B_c)\n",
    "T_r = len(Q_blocks)\n",
    "T_c = len(K_blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q_Block's T_r is 3, so Q_blacks shape must be (T_r, B_r, d) which is (3, 1, 2)\n",
      "Q_blacks shape : (3, 1, 2), Br : 1, N : 2\n"
     ]
    }
   ],
   "source": [
    "# Proof of Step 3\n",
    "Q_blocks = np.array(np.array_split(Q, N // B_r))\n",
    "print(f\"Q_Block's T_r is {Q_blocks.shape[0]}, so Q_blacks shape must be (T_r, B_r, d) which is {Q_blocks.shape}\")\n",
    "print(f\"Q_blacks shape : {Q_blocks.shape}, Br : {B_r}, N : {d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Divide O,l,m each tiles\n",
    "O_tiles = np.array_split(O, T_r)\n",
    "l_tiles = np.array_split(l, T_r)\n",
    "m_tiles = np.array_split(m, T_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Loop in Tc\n",
    "for j in range(T_c):\n",
    "    # 6. Load K_j, V_j from HBM to SRAM\n",
    "    K_j, V_j = K_blocks[j], V_blocks[j]\n",
    "    \n",
    "    # 7. Loop in Tr\n",
    "    for i in range(T_r):\n",
    "        # 8. Load Q ùëñ, O ùëñ, ‚Ñì ùëñ, ùëö ùëñfrom HBM to on-chip SRAM.\n",
    "        # Q_i, O_i, l_i, m_i = Q_blocks[i], O_tiles[i], l_tiles[i], m_tiles[i]\n",
    "        Q_i, O_i, l_i, m_i = Q_blocks[i], O_tiles[i:i+B_r],l_tiles[i:i+B_r],m_tiles[i:i+B_r]\n",
    "        \n",
    "        # 9. Compute Sij = Q_iK^T_j which return Br X Bc\n",
    "        S_ij = np.dot(Q_i, K_j.T) # Orginally on SRAM\n",
    "        # Proof of shape\n",
    "        # print(f\"S_ij.shape:{S_ij.shape} vs B_r X B_c : {B_r,B_c}\")\n",
    "\n",
    "        # 10. Compute i) mhat_ij = rowmax(S_ij) return Br, \n",
    "        #            ii) P_ij = e^(S_ij - mhat_ij) return B_r X B_c, \n",
    "        #           iii) lhat_ij = rowsum(P_ij) return B_r\n",
    "        mhat_ij = np.max(S_ij, axis=1)\n",
    "        P_ij = np.exp(S_ij - mhat_ij)\n",
    "        lhat_ij = np.sum(P_ij, axis=1)\n",
    "        \n",
    "        # 11. Compute i) mnew_i = max(m_i, mhat_ij) return B_r, \n",
    "        #            ii) lnew_i = exp(m_i - mnew_i)l_i + exp(mhat_ij-mnew_i)lhat_ij return B_r\n",
    "        mnew_i = np.maximum(m_i, mhat_ij)\n",
    "        lnew_i = np.exp(m_i - mnew_i)*l_i + np.exp(mhat_ij-mnew_i)*lhat_ij\n",
    "        \n",
    "        # 12. O_i = diag(lnew_i)^-1 * (diag(l_i)exp(m_i - mnew_i)*O_i + exp(mhat_ij-mnew_i)lhat_ij) return B_r\n",
    "        O_i = (np.diag(l_i)*np.exp(m_i - mnew_i) * O_i + np.exp(mhat_ij-mnew_i)*np.dot(P_ij,V_j)) / np.diag(lnew_i)\n",
    "        O_tiles[j][i:i+B_r] = O_i[0][0]\n",
    "        # 13. override\n",
    "        l[i:i+B_r], m[i:i+B_r] = lnew_i[0], mnew_i[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "diag_l_new_i = np.diag(lnew_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.38913363, 0.8367397 ],\n",
       "       [0.50596313, 0.5517325 ],\n",
       "       [0.33130509, 0.89223909]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4061, 0.7114],\n",
       "        [0.4001, 0.7272],\n",
       "        [0.4054, 0.7114]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.nn.functional.scaled_dot_product_attention(torch.Tensor(Q),torch.Tensor(K),torch.Tensor(V))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b8eaaa6818ecebda46680ced9e2f250417589d1dca1355018f6ee4137f9be2c8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.17 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
