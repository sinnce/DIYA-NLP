{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Matrices Q,K,V as (N * d) in HBM, SRAM Size of M\n",
    "N = 6\n",
    "d = 3\n",
    "\n",
    "\n",
    "Q = np.random.rand(N, d)\n",
    "K = np.random.rand(N, d)\n",
    "V = np.random.rand(N, d)\n",
    "M = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Set block size Bc = M/4d, Br = min(M/4d, d)\n",
    "B_c = M // (4 * d)\n",
    "B_r = min(B_c, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Initialize\n",
    "Out = np.zeros((N, d))\n",
    "l = np.zeros(N) #noqa: E741\n",
    "m = np.full(N, -np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Divide Q into Tr which is N/B_r size of Br * d, K,V into Tr N/B_c Bc * d\n",
    "Q_blocks = np.array_split(Q, N // B_r)  # np.array_split returns List of array\n",
    "K_blocks = np.array_split(K, N // B_c)\n",
    "V_blocks = np.array_split(V, N // B_c)\n",
    "T_r = len(Q_blocks)\n",
    "T_c = len(K_blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proof of Step 3\n",
    "Q_blocks = np.array(np.array_split(Q, N // B_r))\n",
    "print(\n",
    "    f\"Q_Block's T_r is {Q_blocks.shape[0]}, so Q_blacks shape must be (T_r, B_r, d) which is {Q_blocks.shape}\"\n",
    ")\n",
    "print(f\"Q_blacks shape : {Q_blocks.shape}, Br : {B_r}, N : {d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Divide O,l,m each tiles\n",
    "O_tiles = np.array_split(Out, T_r)\n",
    "l_tiles = np.array_split(l, T_r)\n",
    "m_tiles = np.array_split(m, T_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Loop in Tc\n",
    "for j in range(T_c):\n",
    "    # 6. Load K_j, V_j from HBM to SRAM\n",
    "    K_j, V_j = K_blocks[j], V_blocks[j]\n",
    "\n",
    "    # 7. Loop in Tr\n",
    "    for i in range(T_r):\n",
    "        # 8. Load Q ùëñ, O ùëñ, ‚Ñì ùëñ, ùëö ùëñ from HBM to on-chip SRAM.\n",
    "        # Q_i, O_i, l_i, m_i = Q_blocks[i], O_tiles[i], l_tiles[i], m_tiles[i]\n",
    "        Q_i, O_i, l_i, m_i = Q_blocks[i], O_tiles[i], l_tiles[i], m_tiles[i]\n",
    "\n",
    "        # 9. Compute Sij = Q_iK^T_j which return Br X Bc\n",
    "        S_ij = np.dot(Q_i, K_j.T)  # Orginally on SRAM\n",
    "        # Proof of shape\n",
    "        # print(f\"S_ij.shape:{S_ij.shape} vs B_r X B_c : {B_r,B_c}\")\n",
    "\n",
    "        # 10. Compute i) mhat_ij = rowmax(S_ij) return Br,\n",
    "        #            ii) P_ij = e^(S_ij - mhat_ij) return B_r X B_c,\n",
    "        #           iii) lhat_ij = rowsum(P_ij) return B_r\n",
    "        mhat_ij = np.max(S_ij, axis=1)  # max per column\n",
    "        # add dimension and broadcas\n",
    "\n",
    "        P_ij = np.exp(S_ij - mhat_ij[:, np.newaxis])\n",
    "        lhat_ij = np.sum(P_ij, axis=1)\n",
    "\n",
    "        # 11. Compute i) mnew_i = max(m_i, mhat_ij) return B_r,\n",
    "        #            ii) lnew_i = exp(m_i - mnew_i)l_i + exp(mhat_ij-mnew_i)lhat_ij return B_r\n",
    "        mnew_i = np.maximum(m_i, mhat_ij)\n",
    "        lnew_i = np.exp(m_i - mnew_i) * l_i + np.exp(mhat_ij - mnew_i) * lhat_ij\n",
    "\n",
    "        # 12. O_i = diag(lnew_i)^-1 * (diag(l_i)exp(m_i - mnew_i)*O_i + exp(mhat_ij-mnew_i)lhat_ij) return B_r\n",
    "        # TODO\n",
    "        O_tiles[i] = (1 / lnew_i)[:, np.newaxis] * (\n",
    "            (l_i * np.exp(m_i - mnew_i))[:,np.newaxis] * O_i\n",
    "            + (np.exp(mhat_ij - mnew_i)[:,np.newaxis] * P_ij) @ V_j\n",
    "        )\n",
    "        # 13. override\n",
    "        l_tiles[i], m_tiles[i] = lnew_i, mnew_i\n",
    "# 14. O = concatenate(O_1, O_2, ... , O_T_r) return N X d\n",
    "out = np.concatenate(O_tiles, axis=0)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vanilla attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = Q @ K.T\n",
    "# apply softmax\n",
    "P = np.exp(S - np.max(S, axis=1, keepdims=True))\n",
    "P = P / np.sum(P, axis=1, keepdims=True)\n",
    "O_ = P @ V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "O_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.nn.functional.scaled_dot_product_attention(torch.Tensor(Q), torch.Tensor(K), torch.Tensor(V))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "# Define the matrix and vector\n",
    "A = np.array([[2, 1], [1, 3]])\n",
    "v = np.array([1, 2])\n",
    "\n",
    "# Calculate the individual column results\n",
    "results = [A[:, i].reshape(-1, 1) * v[i] for i in range(A.shape[1])]\n",
    "\n",
    "# Set up the figure, the axis, and the plot elements\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "ax.set_xlim(-10, 10)\n",
    "ax.set_ylim(-10, 10)\n",
    "ax.grid(True)\n",
    "\n",
    "vector_color = [\"yellow\", \"blue\"]\n",
    "\n",
    "vectors = []\n",
    "\n",
    "for i, res in enumerate(results):\n",
    "    (vec,) = ax.plot([], [], lw=2, color=vector_color[i], label=f\"{v[i]} * Column {i+1}\")\n",
    "    vectors.append(vec)\n",
    "\n",
    "ax.legend()\n",
    "\n",
    "\n",
    "# Initialization function: plot the background of each frame\n",
    "def init():\n",
    "    for vec in vectors:\n",
    "        vec.set_data([], [])\n",
    "    return vectors\n",
    "\n",
    "\n",
    "# Animation function: update the plot for each frame\n",
    "def animate(i):\n",
    "    for j, res in enumerate(results):\n",
    "        if i == j:\n",
    "            vectors[j].set_data([0, res[0]], [0, res[1]])\n",
    "        else:\n",
    "            vectors[j].set_data([], [])\n",
    "    return vectors\n",
    "\n",
    "\n",
    "# Call the animator\n",
    "anim = FuncAnimation(\n",
    "    fig, animate, init_func=init, frames=len(results), repeat=True, blit=True, interval=1000\n",
    ")\n",
    "anim.save(\"matrix-vector-multiplication.gif\", writer=\"pillow\", fps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b8eaaa6818ecebda46680ced9e2f250417589d1dca1355018f6ee4137f9be2c8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.17 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
